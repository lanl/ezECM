---
title: "BayesECM"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{BayesECM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(ezECM)
```

The purpose of this vignette is to walk the user through the workflow and results from categorizing data with a Bayesian ECM model.  The intended workflow for a BayesECM event categorization is as follows:

1.  Load data from known events to use as training data.
2.  Fit a `BayesECM` model to the training data.
3.  Save the `BayesECM` model for later use, this allows for faster categorization of unknown events to be collected in the future.
4.  Observe (an) unknown event(s), organize the collected data and load it into the `R` session
5.  Load the previously fit `BayesECM` model
6.  Feed the model fit and the new data into `predict.BayesECM()` to obtain categorization estimates for the new data
7.  Analyze the categorization estimates

# Loading Data

p-values are loaded into the `R` global environment using the `import_pvals()` function supplied by the `ezECM` package.

```{r}
csv_use <- "good_training.csv"
file_path <- system.file("extdata", csv_use, package = "ezECM")
training_data <- import_pvals(file = file_path, header = TRUE, sep = ",", training = TRUE)
```

`BayesECM()` can handle when the training data is missing entries.  The loaded `data.frame`, named `training_data`, does not contain missing entries, so let's delete some of them for the example.  The code below ensures at least one of the discriminants is available for each event.

```{r}
set.seed(1)
s1 <- sample(1:nrow(training_data), size = 25)
training_data[s1,1] <- NA
s2 <- sample((1:nrow(training_data))[-s1], size = 20)
training_data[s2,2] <- NA
s3 <- sample(1:nrow(training_data), size = 35)
training_data[s3,3] <- NA

```

Inspecting the `training_data`:

```{r}
training_data
```

# Fitting a `BayesECM` Model

With the training data in the `R` environment, the next step is to train the `BayesECM` model.  Training includes organizing the data, pre-computing some values for prediction, and incorporating the supplied values of prior parameters.  Because `training_data` has missing values, the vast bulk of the computation time required for training is from obtaining draws of the missing data entries, given the observed data entries, using Markov chain Monte Carlo (MCMC) methods.  If `training_data` did not have any missing values, computation time for training would be trivial.

The MCMC implementation approximates an integral, by iteratively drawing, or sampling, the missing values from a loop of conditional probability distributions.  Each draw of the missing data is a metaphorical realization of a *coin flip*, a random sample from the range of possible values.  The number of iterations, or draws, the better the approximation of the integral.  However, increasing the number of samples requires the trade off of increased computation time.  The user chooses this trade off as the two element vector supplied to the `BT` argument of `BayesECM()`.  `BT[1]`, the first element of `BT`, stipulates the number of initial **B**urn-in iterations that will be thrown away.  The Markov Chain is rarely initiated with draws from the target distribution, instead the chain must move through several iterations before converging on draws from the target distribution.  Discarding the first draws before convergence is necessary.  As a rough rule of thumb, we recommend setting `BT[1]` from roughly `100` to `1000`.  The second element of `BT`, `BT[2]`, controls the **T**otal number of iterations.  The resulting number of draws of each element of the missing data output from `BayesECM()` is `BT[2]-BT[1]`.  

Next, running the function, here, we can choose `BT = c(1000, 40000)`.  If you would like to watch the progress to understand how much longer fitting the model will take, include `verb = TRUE` in the function arguments.

```{r}
BayesECM_fit <- BayesECM(Y = training_data, BT = c(1000, 40000))
```

To save the fit for later use, so that categorizing new data requires less computation time, the following code can be used to save the object to the local directory.

```{r eval = FALSE}
export_ecm(x = BayesECM_fit, file = "BayesECMfit.rda")
```

# Loading New Data

Sometime later, an event of interest is observed.  p-values are calculated for each discriminant, and the data is collected in a `*.csv` file.  The file can then be loaded into the R session using the `import_pvals()` function.

```{r}
csv_use <- "good_newdata.csv"
file_path <- system.file("extdata", csv_use, package = "ezECM")
newdata <- import_pvals(file = file_path, header = TRUE, sep = ",", training = FALSE)
```

Inspecting the data we can see that some missing data has the `NA` place-holder.  Because the data is from a simulation, the true event is known.

```{r}
newdata
```

We can put the `event` column to the side for now to check the accuracy of the results.

```{r}
newdata_truth <- newdata$event
newdata$event <- NULL
newdata[9,2:3] <- NA

```

# Loading a Previous `BayesECM` Model

It will take less time to load the previously fit model back into the `R` global environment, than to reuse the `BayesECM` function every time a new categorization is required.  Specifying the file path, the previously fit model can be loaded as such:

```{r eval = FALSE}
BayesECM_fit <- import_ecm(file = "BayesECMfit.rda")
```

# Categorizing Unlabled Data

The variable `BayesECM_fit` is a `BayesECM` object within the `R` environment.  The `predict()` function is used to predict the category for each unlabeled event.  In order to reduce computation time, `thinning` is set to `2`.  This choice means that every other parameter draw will be used, `r length(seq(from = 1000, to = 40000, by = 2))` in total.  There are some benefits to drawing a larger number of Monte Carlo samples during training, and then reducing the number of samples used in prediction through thinning, when compared to drawing a smaller number of Monte Carlo samples during training.

```{r}
cat_pred <- predict(object = BayesECM_fit, Ytilde = newdata, thinning = 2)
```

Running this code only took a few seconds.  Remember, for each unlabeled event there is some probability that the event belongs in one of the two event categories.  There is uncertainty in these probabilities, and `cat_pred` contains samples from the distribution of these probabilities.  The expected probability that each unlabeled event belongs to each category can easily be viewed with `summary()`.

# Analysis of the Results


The output from `BayesECM.predict()` can be used to easily plot the results for a specified event.  The argument `index` specifies the event contained in row number of `newdata` the user wants to plot.

```{r}
plot(x = cat_pred, index = 5)
```

The category labels in the legend are originally taken from the `event` column used in the training data.  Plotting again, using the `cat_labels` argument, we can capitalize (or completely change) the text in the legend without manipulating the data structure.

```{r}
plot(x = cat_pred, index = 5, cat_labels = c("Earthquake", "Explosion"))
```

We can see from these results that for the event corresponding to the second row of `newdata`, we expect there is a 63\% chance the event is an explosion.  However, there is some uncertainty in the results.  Since the data used was simulated, we can check the truth:

```{r}
newdata_truth[5]
```

Looking at the data can provide some insight as to why this categorization had uncertainty. The p-value for event depth is not in a rejection region, however the value becoming fairly low.  Likely the more important issue is that `p.polarity` is missing.  `BayesECM()` may have a more difficult time distinguishing between the two categories when `p.polarity` is missing, which is reflected in the variance of the distributions.

```{r}
newdata[5,]
```
In comparison, plotting the ninth unlabeled data point, by setting `index = 1`, shows a more decisive result:

```{r}
plot(x = cat_pred, index = 1, cat_labels = c("Earthquake", "Explosion"))
```

Inspecting the data for this event

```{r}
newdata[1,]
```
and peeking at the truth

```{r}
newdata_truth[1]
```

shows an explosion with all the discriminants provided.  `p.depth` is still fairly far from a rejection region, and similarly `p.polarity` is fairly large.
