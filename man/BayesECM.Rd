% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Bayes-ECM.R
\name{BayesECM}
\alias{BayesECM}
\title{Bayesian Event Matrix Categorization}
\usage{
BayesECM(
  Y,
  BT = c(100, 1000),
  priors = "default",
  verb = FALSE,
  transform = "logit"
)
}
\arguments{
\item{Y}{\code{data.frame} of training data, with rows corresponding to \eqn{N} individual events, and columns corresponding to \eqn{p} discriminants.  An additional column named \code{"event"} is required, which labels each row with the known event category.  Missing data is specified with \code{NA}.  \code{dim(Y)} must equal \code{c(N, p + 1)}.}

\item{BT}{integer vector of length 2.  Used to specify the number \code{c("Burn-in", "Total")} Markov-Chain Monte-Carlo samples drawn.  \code{BT[1]} stipulates the number of initial \emph{Burn-in} samples to discard, while \code{BT[2]} stipulates the total number of samples.}

\item{priors}{list of parameters to be used in the prior distributions for model parameters.  See details.}

\item{verb}{logical.  A setting of \code{TRUE} prints a progress bar as samples are drawn and warnings when they occur.}

\item{transform}{character string specifying the transform to use on the elements of\code{Y} before fitting the model.  Options are \code{"logit"} and \code{"arcsin"} with \code{"logit"} being the default.  See details.}
}
\value{
Returns an object of \code{class("BayesECM")}.  If there are missing data in the supplied argument \code{Y} the object contains Markov-Chain Monte-Carlo samples of the imputed missing data.  Prior distribution parameters used are always included in the output.  The primary use of an object returned from \code{\link[=BayesECM]{BayesECM()}} is to later use this object to categorize unlabeled data with the \code{\link[=predict.BayesECM]{predict.BayesECM()}} function.
}
\description{
Training a Bayesian ECM model
}
\details{
The output of \code{BayesECM()} provides a fitted Bayesian Event Categorization Matrix (B-ECM) model, utilizing the data and prior parameter settings .  If there are missing values in \code{Y}, these values are imputed.  If no values are missing, training is perceptually instantaneous for all but very large data sets.  The next step for categorization is prediction of the category of a new observation, via the \code{\link[=predict.BayesECM]{predict.BayesECM()}} function.
\subsection{Data Prep}{

Before the data in \code{Y} is used with the model, the p-values \eqn{\in (0,1]} are transformed in an effort to better align the data with some properties of the normal distribution.  When \code{transform == "logit"} the inverse of the logistic function \eqn{Y_{N \times p} = \log\left(\texttt{Y}\right) - \log\left(1-\texttt{Y}\right)} maps the values to the real number line.  Values of \code{Y} exactly equal to 0 or 1 cannot be used when \code{transform == "logit"}.  Setting the argument \code{transform == "arcsin"} uses the transformation \eqn{Y_{N\times p} = 2/\pi \times \mathrm{arcsin}\sqrt{Y}} further described in \insertCite{anderson2007mathematical;textual}{ezECM}.  From here forward, the variable \eqn{Y_{N \times p}} should be understood to be the transformation of \code{Y}, where \eqn{N} is the total number of rows in \code{Y} and \eqn{p} is the number of discriminant columns in \code{Y}.
}

\subsection{The Model}{

The B-ECM model structure can be found in a future publication with the working title "Bayesian Event Categorization Matrix Approach for Nuclear Detonations".  Some details from this publication are reproduced here.

Bayesian ECM assumes that all data is generated using a mixture of \eqn{K} normal distributions, each with a mean of \eqn{\mu_k}, a covariance of \eqn{\Sigma_k}.  Each event category is represented by one of the \eqn{K} distributions.

\deqn{\sum_{k = 1}^K \pi_k \mathcal{N}(y^i_p; \mu_k, \Sigma_k)}

Each Gaussian distribution in the sum is normalized by \eqn{\pi_k}, where \eqn{\sum_{k=1}^K \pi_k =1}.  \eqn{y^i_p} corresponds to a vector of length \eqn{p}.

There are prior distributions on each \eqn{\mu_k, \Sigma_k}, and \eqn{\pi}.  These prior distributions are detailed below.  The posterior distributions of these parameters, given \eqn{Y_{N \times p}}, is integrated over analytically, which reduces computation time for training.  Integration results in the marginal likelihood of each component in the mixture to be matrix t-distributed.

\code{BayesECM()} can handle observations where only some of the \eqn{p} discriminants have been observed, by imputing these missing values given the rest of the data.  The properties of the conditional matrix t-distribution are used in this step.
}

\subsection{Prior Distributions}{

The distributions  \eqn{p(\mu_k|Y_{N_k \times p})}, \eqn{p(\Sigma|Y_{N_k \times p})}, and \eqn{p(\pi|Y_{N \times p})} are dependent on the specifications of prior distributions  \eqn{p(\mu|\Sigma, \eta_k)}, \eqn{p(\Sigma| \Psi_k, \nu_k)}, and \eqn{p(\pi|\alpha)}.  The ability to use \code{"default"} priors has been included for ease of use.

\eqn{p(\mu_k|\Sigma_k, \eta_k)} is a multivariate normal distribution with a mean of \eqn{\eta_k} and is conditional on the covariance \eqn{\Sigma_k}.   \eqn{p(\Sigma_k|\nu_k, \Psi_k)} to be equivalent, as an \href{https://en.wikipedia.org/wiki/Wishart_distribution}{Inverse Wishart} distribution with degrees of freedom parameter \eqn{\nu}, or \code{nu}, and scale matrix \eqn{\Psi}, or \code{Psi}.  \eqn{p(\pi)} is a \href{https://en.wikipedia.org/wiki/Dirichlet_distribution}{Dirichlet distribution} with the parameter vector \eqn{\alpha} of length \eqn{K}.

. The defaults are \eqn{\eta_k} is a vector of zeros of length \eqn{p}, \eqn{\Psi_k} is the identity matrix, and each element of \eqn{alpha} is \eqn{K/2}. Use of default prior parameters for parameters and all event categories can be specified by setting the argument \code{priors = "default"}.  If all prior parameters are to be shared between all event categories, but some non-default values are desirable then supplying a list of a similar structure to \code{priors = list(eta = "default", Psi = "default", nu = 50, alpha = 10)} can be used, where \code{"default"} can be exchanged for the correct data structure for any of the parameters in the list and vice-versa.

If one wishes to use some default values, but not share all parameter values between each event category, or wishes to specify each parameter value individually with no defaults, we suggest running and saving the output \code{BayesECM(Y = Y, BT = c(1,2))$priors}.  Modifying the elements of the list accordingly, and then setting the \code{priors} argument equal to the moddified list on a subsequent call to \code{BayesECM()} will produce the desired behavior.  Note that when specifying \code{eta} or \code{Psi} it is necessary that the row and column order of the supplied values corresponds to the column order of \code{Y}.

For user specified prior parameters, the current implementation of \code{BayesECM()} utilizes the same prior on each component of the mixture.  Inspection of the output of \code{BayesECM()} reveals how these parameters should be provided as the \code{priors} argument to a call of \code{BayesECM()}.
}
}
\examples{

csv_use <- "good_training.csv"
file_path <- system.file("extdata", csv_use, package = "ezECM")
training_data <- import_pvals(file = file_path, header = TRUE, sep = ",", training = TRUE)

trained_model <- BayesECM(Y = training_data)


}
